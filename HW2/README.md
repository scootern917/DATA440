# HW2

## Part 1
(5 points) Create your class that implements the Gradient Boosting concept, based on the locally weighted regression method (Lowess class), and that allows a user-prescribed number of boosting steps. The class you develop should have all the mainstream useful options, including “fit,” “is_fitted”, and “predict,” methods. Show applications with real data for regression, 10-fold cross-validations and compare the effect of different scalers, such as the “StandardScaler”, “MinMaxScaler”, and the “QuantileScaler”. In the case of the “Concrete” data set, determine a choice of hyperparameters that yield lower MSEs for your method when compared to the eXtream Gradient Boosting library.


## Part 2
(5 points) Implement your own version of Locally Weighted Logistic Regression and compare its performance on the Iris data set with the version presented in this article: https://calvintchi.github.io/classical_machine_learning/2020/08/16/lwlr.html.


Present your results with detailed explanations and visualizations of the results in the format of a data science paper on GiHub.
