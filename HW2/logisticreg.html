<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Project 2: Locally Weighted Logistic Regression</title>

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Calibri:wght@400;600&display=swap" rel="stylesheet">

    <!-- Basic Styles -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Calibri', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f4f4f4;
            padding: 20px;
        }

        header {
            background-color: #0077b6;
            color: white;
            padding: 20px;
            text-align: center;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        nav {
            margin-top: 20px;
        }

        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
        }

        nav ul li {
            margin: 0 15px;
        }

        nav ul li a {
            color: white;
            text-decoration: none;
            font-weight: 600;
        }

        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 20px;
            background: white;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .hero {
            text-align: center;
            padding: 50px 0;
            background-color: #90e0ef;
            border-radius: 8px;
            margin-bottom: 30px;
        }

        .hero h2 {
            font-size: 2em;
            margin-bottom: 15px;
        }

        .hero p {
            font-size: 1.1em;
        }

        footer {
            margin-top: 40px;
            text-align: center;
            padding: 20px;
            background-color: #0077b6;
            color: white;
        }

        footer p {
            font-size: 0.9em;
        }

        @media(max-width: 768px) {
            .cards {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>

    <header>
        <h1>Project 2 Part 2: Locally Weighted Logistic Regression & Comparison's to Calvin Chi's XGBoost</h1>
    </header>

    <div class="container">
    <h3>Locally Weighted Logistic Regression</h3>
        <p>Locally Weighted Logistic Regression (LWLR) is a non-parametric extension of logistic regression that fits a local model for 
            each query point. Using a kernel function (e.g., Gaussian), it assigns higher weights to nearby training points, emphasizing 
            local patterns. This allows LWLR to adapt to complex, non-linear decision boundaries without imposing global assumptions. 
            While flexible and effective for localized relationships, it can be computationally expensive, as it requires solving a 
            weighted logistic regression for each prediction.</p>

    <img src="https://calvintchi.github.io/assets/img/Locally-weighted_logistic_regression_files/Locally-weighted_logistic_regression_10_1.png" 
        alt="Locally Wighted Decision Boundary example" style="width:250px; height:250px"/>
    <p><a href="https://github.com/scootern917/DATA440/blob/main/HW2/Logistic.py" target="_blank">Here</a> is my class for the LWLR. 
        <a href="https://github.com/scootern917/DATA440/blob/main/HW2/Implementation.ipynb" target="_blank"> Here</a> is my implementation 
        on the iris dataset, where the results of the model are compared to Calvin Chi's XGBoost, which can be found 
        <a href="https://calvintchi.github.io/classical_machine_learning/2020/08/16/lwlr.html" target="_blank">Here.</a> The model I created,
        in conjunction with Gradient Boosting, performs better on the iris dataset than XGBoost. Since in the iris dataset has three 
        classifications, three separate logistic regression models were created. These three models are:
        
        * Setosa vs Not Setosa
        * Versicolour vs Not Versicolour
        * Virginia vs Not Virginia
        Each model gives a probability that an observation belongs in the corresponding class. The class with the highest probability is
        determined as the final prediction

Setosa vs Not setosa
Versicolour vs Not Versicolour
Virginia vs Not Virginia
    </p>
    </div>

    <footer>
        <p>&copy; 2024 My DATA440 Website. All rights reserved.</p>
    </footer>

</body>
</html>
